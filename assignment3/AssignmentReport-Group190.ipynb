{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 3 Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an outline for your report to ease the amount of work required to create your report. Jupyter notebook supports markdown, and I recommend you to check out this [cheat sheet](https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet). If you are not familiar with markdown.\n",
    "\n",
    "Before delivery, **remember to convert this file to PDF**. You can do it in two ways:\n",
    "1. Print the webpage (ctrl+P or cmd+P)\n",
    "2. Export with latex. This is somewhat more difficult, but you'll get somehwat of a \"prettier\" PDF. Go to File -> Download as -> PDF via LaTeX. You might have to install nbconvert and pandoc through conda; `conda install nbconvert pandoc`.\n",
    "\n",
    "\n",
    "# For TA: The models were trained using the enclosed ipynb: ```TDT4265_Assignment3_Group190.ipynb```. I have copied the relevant code into .py files if you require them to run but there is no guarantee that it would work as my computer has difficulty setting up a local copy of pytorch. The ipynb would run if it is required to replicate my work. It was trained on Google Colab with a P100."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## task 1a - 1c)\n",
    "\n",
    "![task1a_1.png](task1a_1.png)\n",
    "![task1a_2.png](task1a_2.png)\n",
    "![task1a_3_1b_1c.png](task1a_3_1b_1c_1.png)\n",
    "\n",
    "\n",
    "## task 1c - 1e)\n",
    "\n",
    "![task1c_2_1d_1e.png](task1c_2_1d_1e.png)\n",
    "\n",
    "\n",
    "## task 1f - 1g)\n",
    "\n",
    "![task1f_1g_1.png](task1f_1g_1.png)\n",
    "![task1g_2.png](task1g_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2\n",
    "\n",
    "### Task 2a)\n",
    "![task2_loss_plot.png](task2_loss_plot.png)\n",
    "\n",
    "### Task 2b)\n",
    "Final accuracies\n",
    "\n",
    "| Train | Validation | Test |\n",
    "| --- | --- | --- |\n",
    "| 0.8293 | 0.7184 | 0.7127 |\n",
    "\n",
    "Epoch: 17"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3a)\n",
    "**Model 1**\n",
    "\n",
    "```\n",
    "Optimizer : SGD\n",
    "Learning Rate: 1e-2\n",
    "Data Augmentation:  Normalization with mean = (0.5, 0.5, 0.5) and std = (0.25, 0.25, 0.25)\n",
    "Batch Size: 64\n",
    "Epochs: 10\n",
    "Early Stop: 10\n",
    "```\n",
    "\n",
    "| Layer Num | Layer Type | Number of Hidden Units / Num Filter | Kernel Size / Padding / Stride | Activation Function |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| 1 | Conv2D | 32 | 5 / 2 / 1 | ReLU |\n",
    "| 2 | Conv2D | 64 | 5 / 2 / 1 | ReLU |\n",
    "| 3 | Conv2D | 128 | 5 / 2 / 1 | ReLU |\n",
    "| 3 | MaxPool2D | - | 2 / 0 / 2 | - |\n",
    "| 3 | BatchNorm2D | 128 | - | - |\n",
    "| 4 | Conv2D | 256 | 3 / 1 / 1 | ReLU |\n",
    "| 5 | Conv2D | 512 | 3 / 1 / 1 | ReLU |\n",
    "| 6 | Conv2D | 1024 | 3 / 1 / 1 | ReLU |\n",
    "| 6 | MaxPool2D | - | 2 / 0 / 2 | - |\n",
    "| 6 | BatchNorm2D | 1024 | - | - |\n",
    "| - | - | - | - | - |\n",
    "| 7 | Flatten | - | - | - |\n",
    "| 8 | Linear | 128 | - | ReLU |\n",
    "| 9 | Linear | 128 | - | ReLU |\n",
    "| 10 | Linear | 10 | - | Softmax |\n",
    "\n",
    "Idea: Replicating a Residual Block's use of sequential convolution layers to extract more complex features, together with the idea of using different sized kernels to extract features of different sizes from InceptionNets. Decided to exclude skip connections as the model is relatively small and the use of BatchNorm2D can reduce the impact of exploding / vanishing gradients.\n",
    "\n",
    "Early stop at 8 epoch with 0.81 test accuracy, 0.812 validation accuracy.\n",
    "\n",
    "\n",
    "**Model 2**\n",
    "\n",
    "```\n",
    "Optimizer : SGD\n",
    "Learning Rate: 1e-2\n",
    "Data Augmentation: Normalization with mean = (0.5, 0.5, 0.5) and std = (0.25, 0.25, 0.25)\n",
    "Batch Size: 64\n",
    "Epochs: 10\n",
    "Early Stop: 10\n",
    "```\n",
    "\n",
    "| Layer Num | Layer Type | Number of Hidden Units / Num Filter | Kernel Size/Padding/Stride | Activation Function |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| 1 | Conv2D | 32 | 3 / 2 / 1 | ReLU |\n",
    "| 1 | MaxPool2D | - | 2 / 0 / 2 | - |\n",
    "| 2 | Conv2D | 64 | 3 / 2 / 1 | ReLU |\n",
    "| 2 | BatchNorm2D | 64 | - | - |\n",
    "| 3 | Conv2D | 128 | 5 / 2 / 1 | ReLU |\n",
    "| 3 | MaxPool2D | - | 2 / 0 / 2 | - |\n",
    "| 4 | Conv2D | 256 | 5 / 2 / 1 | ReLU |\n",
    "| 4 | BatchNorm2D | 256 | - | - |\n",
    "| 5 | Conv2D | 512 | 7 / 2 / 1 | ReLU |\n",
    "| 5 | MaxPool2D | - | 2 / 0 / 2 | - |\n",
    "| - | - | - | - | - |\n",
    "| 6 | Flatten | - | - | - |\n",
    "| 7 | Linear | 64 | - | ReLU |\n",
    "| 8 | Linear | 10 | - | Softmax |\n",
    "\n",
    "Idea: Alternation of MaxPool2D and BatchNorm2D after Conv2D layers. Incremental size of kernels from 3, 5 to 7 for every 2 layers. Intuition is to build more complex features based on simpler features described by smaller kernels (E.g. lines, curves). MaxPool2D to reduce noise and BatchNorm2D to prevent issues of vanishing / exploding gradients.\n",
    "\n",
    "Stops at 10 epochs with 0.808 test accuracy and 0.817 validation accuracy.\n",
    "\n",
    "### Task 3b)\n",
    "Include final accuracy scores and plot for two models\n",
    "\n",
    "**Model 1 Final Scores**\n",
    "\n",
    "|Train Loss|Train Accuracy|Validation Accuracy|Test Accuracy|\n",
    "|---|---|---|---|\n",
    "|0.0007|1.0000|0.8096|0.8046|\n",
    "\n",
    "\n",
    "**Model 2 Final Scores**\n",
    "\n",
    "|Train Loss|Train Accuracy|Validation Accuracy|Test Accuracy|\n",
    "|---|---|---|---|\n",
    "|0.0033|1.0000|0.8146|0.8114|\n",
    "\n",
    "\n",
    "**Conclusion: Model 2 is better marginally by 0.7%**\n",
    "\n",
    "\n",
    "\n",
    "**Model 2 (Best)**\n",
    "\n",
    "![task3_accuracy_plot.png](task3_accuracy_plot.png)\n",
    "![task3_loss_plot.png](task3_loss_plot.png)\n",
    "\n",
    "### Task 3c)\n",
    "1. Order of Convolution Layers\n",
    "    - Saw improvements when convolution layers were sequential before a MaxPool layer such as in Table 1\n",
    "    - Performance improved from 0.71 to 0.75.\n",
    "    - This could be because more complex layers could be detected before MaxPooling which might have removed such information.\n",
    "\n",
    "\n",
    "2. More Convolution Layers\n",
    "    - Saw significant improvements by simply increasing the number of convolution layers that the model has.\n",
    "    - This could be due to the model being able to identify more complex features by combining features identified at earlier in the network. \n",
    "    - This increased performance the most from 0.75 to 0.81.\n",
    "    \n",
    "\n",
    "3. Increasing number of hidden units at FC layer / Increase the number of FC layers.\n",
    "    - No significant improvement\n",
    "    - Perhaps there isn't much information loss at this layer and more information / patterns can be extracted from the convolution stack instead.\n",
    "\n",
    "\n",
    "4. Implementation of Dropout Layers at the FC layer\n",
    "    - Did not see significant improvements, except that the model took longer to converge / early stop.\n",
    "    - Perhaps this is due to dropout layers forcing the model to find a more reliable pattern by reducing reliance on specific nodes. The model could have insufficient complexity to do so and hence no significant performance gain was realized and the degree of overfitting stayed the same.\n",
    "    \n",
    "    \n",
    "5. Large convolution layer with kernel size == size of input to this layer.\n",
    "    - No significant improvements\n",
    "    - Perhaps the FC layer is sufficient to perform such a task, albeit at a higher computation cost with less shared weights.\n",
    "    \n",
    "    \n",
    "6. MaxPool2D first, or BatchNorm2D first?\n",
    "    - Found that MaxPool2D first gave a 1-2% accuracy increase over 5 runs.\n",
    "    - May be inconclusive as to which is better.\n",
    "    - Order outlined in [this paper](https://stackoverflow.com/questions/42015156/the-order-of-pooling-and-normalization-layer-in-convnet) explains that BatchNorm2D first might lead to some nodes not activating when they should due to the normalization function.\n",
    "\n",
    "\n",
    "### Task 3d)\n",
    "![task3d.png](task3d.png)\n",
    "\n",
    "We saw improvement of accuracy from 0.75 to 0.81.\n",
    "\n",
    "### Task 3e)\n",
    "**Model 3**\n",
    "\n",
    "```\n",
    "Optimizer : SGD\n",
    "Learning Rate: 1e-2\n",
    "Data Augmentation: None\n",
    "Batch Size: 64\n",
    "Epochs: 10\n",
    "Early Stop: 10\n",
    "```\n",
    "\n",
    "| Layer Num | Layer Type | Number of Hidden Units / Num Filter | Kernel Size / Padding / Stride | Activation Function |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| 1 | Conv2D | 32 | 3 / 1 / 1 | ReLU |\n",
    "| 2 | Conv2D | 64 | 3 / 1 / 1 | ReLU |\n",
    "| 3 | Conv2D | 128 | 3 / 1 / 1 | ReLU |\n",
    "| 3 | MaxPool2D | - | 2 / 0 / 2 | - |\n",
    "| 3 | BatchNorm2D | 128 | - | - |\n",
    "| 4 | Conv2D | 256 | 5 / 2 / 1 | ReLU |\n",
    "| 5 | Conv2D | 512 | 5 / 2 / 1 | ReLU |\n",
    "| 6 | Conv2D | 1024 | 5 / 2 / 1 | ReLU |\n",
    "| 6 | MaxPool2D | - | 2 / 0 / 2 | - |\n",
    "| 6 | BatchNorm2D | 1024 | - | - |\n",
    "| - | - | - | - | - |\n",
    "| 7 | Flatten | - | - | - |\n",
    "| 8 | Linear | 64 | - | ReLU |\n",
    "| 10 | Linear | 10 | - | Softmax |\n",
    "\n",
    "Idea: Incorporating ideas from ```Model 1``` and ```Model 2```, I order the kernels with smaller sizes first to try and get smaller features, while using larger kernels later to develop more complex features. I also used padding to keep the image the same size to allow longer networks.\n",
    "\n",
    "![task3e.png](task3e.png)\n",
    "\n",
    "Final test accuracy: >=0.83\n",
    "\n",
    "\n",
    "### Task 3f)\n",
    "Yes there are signs of overfitting. The training accuracy has hit 1 but the validation and test accuracy is still at 0.83, indicating that the model has overfitted.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4a)\n",
    "\n",
    "```\n",
    "Optimizer: Adam\n",
    "Batch Size: 32\n",
    "Learning Rate: 5e-5\n",
    "Data Augmentations: Resize to (224, 244) and Normalize with mean = [0.485, 0.456, 0.406] and std = [0.229, 0.224, 0.225]\n",
    "Epochs = 5\n",
    "Early Stopping Count = 4\n",
    "```\n",
    "\n",
    "![task4a.png](task4a.png)\n",
    "\n",
    "Final Test Accuracy: 0.907\n",
    "\n",
    "\n",
    "## Task 4b)\n",
    "![task4b_3.png](task4b_3.png)\n",
    "The activation seems to be rather general. Some seems to have activations at concentrations of different colours. The first two also looks as if it is trying to find lines across the center, vertically and horizontally respectively.\n",
    "\n",
    "\n",
    "## Task 4c)\n",
    "\n",
    "![images/zebra.jpg](images/zebra.jpg)\n",
    "![task4c_2.png](task4c_2.png)\n",
    "\n",
    "It seems that the activations largely occur where the zebra is in the picture. Some may be the head, the body or the legs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
