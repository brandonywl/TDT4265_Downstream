{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 190 Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an outline for your report to ease the amount of work required to create your report. Jupyter notebook supports markdown, and I recommend you to check out this [cheat sheet](https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet). If you are not familiar with markdown.\n",
    "\n",
    "Before delivery, **remember to convert this file to PDF**. You can do it in two ways:\n",
    "1. Print the webpage (ctrl+P or cmd+P)\n",
    "2. Export with latex. This is somewhat more difficult, but you'll get somehwat of a \"prettier\" PDF. Go to File -> Download as -> PDF via LaTeX. You might have to install nbconvert and pandoc through conda; `conda install nbconvert pandoc`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## task 1a)\n",
    "\n",
    "Intersection over Union (IOU) is a metric of how accurate a model's prediction of bounding boxes. It is obtained by using the union and intersection of the overlapping areas between the predicted (P) and actual (A) bounding boxes.\n",
    "\n",
    "It's formula is:\n",
    "\n",
    "$$IOU = \\frac{Area\\;Of\\;Intersection\\;}{\\; Area\\;Of\\;Union} $$\n",
    "\n",
    "\n",
    "We can get the area of intersection by the following:\n",
    "\n",
    "$$X Overlap = max(0, min(P.right, A.right) - max(P.left, A.left))$$\n",
    "$$Y Overlap = max(0, min(P.bottom, A.bottom) - max(P.top, A.top))$$\n",
    "\n",
    "Bottom and top are the bottom most y coordinate and top most y coordinate for the boxes respectively.\n",
    "\n",
    "Right and left are the right most x coordinate and the left most left coordinate for the boxes respectively.\n",
    "\n",
    "<br><br>\n",
    "\n",
    "The area of intersection is then obtained by multiplying the x and y overlaps with the area of a rectangle formula.\n",
    "\n",
    "We can get the area of union by getting the area of both bounding boxes, add them together and minus the area of intersection.\n",
    "\n",
    "<br><br>\n",
    "In these examples, the green box is the predicted box and red is the actual box. We are looking at trying to detect an arrow in the image.\n",
    "\n",
    "![wrong_area_bbox.png](wrong_area_bbox.png)\n",
    "\n",
    "The two boxes are not touching and the area of intersection would be 0, hence the IOU would be 0.\n",
    "\n",
    "![too_small_bbox.png](too_small_bbox.png)\n",
    "\n",
    "In this instance, the bounding box predicted is not as large as we like. The area of intersection would be the size of the predicted bounding box (assume to be 100 units^2) and the area of union would be the size of the actual bounding box (assume to be 144 units^2). This gives us an IOU of 0.69.\n",
    "\n",
    "![good_match_bbox.png](good_match_bbox.png)\n",
    "\n",
    "In this last example, the bounding box predicted is sufficiently large and is quite close to the actual location of the bounding box. Hence the area of intersection is high and the area of union would be quite close to the area of intersection. This would then give us a decently high IOU value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## task 1b)\n",
    "\n",
    "$$Precision = \\frac{True\\;Positives}{True\\;Positives+False\\;Positives} $$\n",
    "\n",
    "\n",
    "$$Recall = \\frac{True\\;Positives}{True\\;Positives+False\\;Negatives} $$\n",
    "\n",
    "True positives are when we predict a positive and the actual result is a positive. A false positive is when we predict a positive and the actual result is a negative.\n",
    "\n",
    "## task 1c)\n",
    "\n",
    "![task1c.jpg](task1c.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2\n",
    "\n",
    "### Task 2f)\n",
    "![precision_recall_curve.png](task2/precision_recall_curve.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3a)\n",
    "The process is called non-maximum suppression.\n",
    "\n",
    "### Task 3b)\n",
    "False. At the later layers, the resolution of the feature maps are actually smaller and each output would represent a larger entity rather than a smaller one.\n",
    "\n",
    "### Task 3c)\n",
    "In real life, boundary boxes do not have an arbitrary boundary box. Cars have similar shapes, humans have similar height/width ratio across everyone. Even when looking at the dataset for self-driving cars, we observe highly clustered distributions of height/width for classes. \n",
    "\n",
    "By using each default bounding box to predict a specfic class as well as it's offsets, we reduce the search space.\n",
    "\n",
    "We then use different default bounding boxes at the same spatial location as objects may be overlapping and hence not represented in just one default bounding box.\n",
    "\n",
    "### Task 3d)\n",
    "YOLO looks at a single-scale feature map while SSD looks at a multiple scale feature map such as the 6 convolution layers it uses to generate the 8732 predictions.\n",
    "\n",
    "YOLO also uses k-means clustering to determine the clusters of default bounding boxes and their aspect ratios. SSD reduces the complexity by manually selecting the aspect ratio carefully to consider the wide spectrum of real life contexts. They also reduce the number of default boxes to a minimum at 4 or 6.\n",
    "\n",
    "### Task 3e)\n",
    "Number of cells = 38 * 38 = 1444 cells\n",
    "\n",
    "With 6 anchors per cell,\n",
    "\n",
    "Number of anchors = 1444 * 6 = 8664 anchors\n",
    "\n",
    "### Task 3f)\n",
    "\n",
    "Number of cells = 38 * 38 + 19 * 19 + 10 * 10 + 5 * 5 + 3 * 3 + 1 * 1 = 1940 cells\n",
    "\n",
    "Number of anchors = 1940 * 6 = 11640 anchors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4b)\n",
    "\n",
    "![Regression_loss.png](Regression_loss.png)\n",
    "\n",
    "The model first hit mAP@0.5 > 0.75 at 16 epochs with 0.756. It is also the higest mAP value.\n",
    "\n",
    "## Task 4c)\n",
    "FILL IN ANSWER. \n",
    "\n",
    "\n",
    "## Task 4d)\n",
    "FILL IN ANSWER. \n",
    "\n",
    "\n",
    "## Task 4e)\n",
    "FILL IN ANSWER. \n",
    "\n",
    "\n",
    "## Task 4f)\n",
    "FILL IN ANSWER. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
